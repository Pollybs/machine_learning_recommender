{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import plotly_express as px\n",
    "import warnings\n",
    "import collections\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rober\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "#tokens = word_tokenize(text)\n",
    "#tokens[:15]\n",
    "# stemming cleaning technique -> treats prefixes and suffixes. NOT USED\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "# stemmed = [ps.stem(w) for w in tokens]\n",
    "#stemmed[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\rober\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet') # wordnet is the most well known lemmatizer for english\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "#lemmatized = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "#lemmatized[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color='CornflowerBlue'><center><strong>I. <ins>Doing some more cleaning - Stop Words </ins> </strong><center><font color='blue'></font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"recipes_10_lem.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lemmatized\"] = df[\"lemmatized\"].str.replace(\"', '\",\" \" ).str.replace(\"['\", \"\").str.replace(\"']\", \"\").str.replace(\"nan \", \"\")\n",
    "df[\"lemmatized\"] = df[\"lemmatized\"].str.replace(\"nan\", \"\") #clean the string transform into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lemmatized\"] = df[\"lemmatized\"].str.split(\" \") #transform into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rober\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"lemmatized2\"] = df[\"lemmatized\"].apply(lambda lemmatized: [word for word in lemmatized if not word in stopwords.words()])\n",
    "#df.to_csv(\"recipes_10_lem.csv\", index=False)\n",
    "\n",
    "# this took 625 m to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv(\"recipes_10_lem.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(new_df[\"lemmatized2\"][0])\n",
    "\n",
    "new_df[\"lem_list\"]  = new_df[\"lemmatized2\"].str.replace(\"', '\",\" \" ).str.replace(\"['\", \"\").str.replace(\"']\", \"\").str.replace(\"nan \", \"\") #clean the string transform into a list\n",
    "#new_df[\"lem_list\"] = new_df[\"lem_list\"].str.replace(\"nan\", \"\") \n",
    "new_df = new_df.rename(columns={\"lem_list\": \"lems_string\", \"lemmatized2\": \"no_stop_word\"})\n",
    "new_df = new_df.drop(columns=\"lem_str\")\n",
    "\n",
    "\n",
    "new_df.to_csv(\"recipes_10_lem.csv\", index=False)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_f = df[(df[\"website_id\"] != 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "website_id\n",
       "3    494963\n",
       "1       573\n",
       "4       285\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f[\"website_id\"].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfs.to_csv(\"recipes_10_lem.csv\")\n",
    "##dfs = pd.read_csv(\"recipes_10_lem.csv\")\n",
    "#dfs.shape\n",
    "#dfs.reset_index(inplace=True)\n",
    "dfs = df.reset_index(drop=True)\n",
    "dfs.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_recipe():\n",
    "    user_recipe = input(\"Give me a recipe that you like:\")\n",
    "    return user_recipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_char = CountVectorizer(analyzer='char_wb', ngram_range = (2,2))\n",
    "list_recipes = list(dfs[\"recipe\"])\n",
    "#user_recipe= user_recipe()\n",
    "user_recipe = 'ratatouile' \n",
    "list_recipes.append(user_recipe)\n",
    "count_matrix = cv_char.fit_transform(list_recipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix = cv_char.fit_transform(list_recipes)\n",
    "cosine_sim = cosine_similarity(count_matrix)\n",
    "similar_recipes = list(enumerate(cosine_sim[-1]))\n",
    "sorted_similar_recipes = sorted(similar_recipes,key=lambda x:x[1],reverse=True)[1:]\n",
    "suggested_id = [d[0] for d in sorted_similar_recipes[:1]] # returns just one recipe\n",
    "re_user = dfs.loc[suggested_id]\n",
    "print(suggested_id)\n",
    "print(re_user)\n",
    "#for x in suggested_id:\n",
    "    #print(str(dfs[\"recipe\"][x]))\n",
    "\n",
    "### inputing the recipe\n",
    "\n",
    "vege_df = dfs[(dfs[\"diet_id\"] == 1) | (dfs[\"diet_id\"] == 2)]\n",
    "#vege_df.head(1)\n",
    "#vege_df[\"diet_id\"].value_counts()\n",
    "#vege_df[\"website_id\"].value_counts()\n",
    "#vege_df.shape\n",
    "#vege_df.to_csv(\"vege_df.csv\")\n",
    "#vege_df = pd.read_csv(\"vege_df.csv\")\n",
    "cv = CountVectorizer()\n",
    "#re_user = dfs.loc[suggested_id]\n",
    "df_search = pd.concat([vege_df, re_user], axis=0)\n",
    "df_search = df_search.reset_index(drop=True)\n",
    "list_features = list(df_search[\"lemmatized2\"])\n",
    "count_matrix = cv.fit_transform(list_features)\n",
    "\n",
    "cosine_sim = cosine_similarity(count_matrix)\n",
    "similar_recipes = list(enumerate(cosine_sim[-1]))\n",
    "sorted_similar_recipes = sorted(similar_recipes,key=lambda x:x[1],reverse=True)[1:]\n",
    "suggested_ids = [d[0] for d in sorted_similar_recipes[:5]]\n",
    "final_recipes = df_search.loc[suggested_ids]\n",
    "final_recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'['"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_features[1861]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['1                                                                                                                                                                                                                     butternut squash                                                                                                                                                                , (1.2kg)', '250                                                                                                                                                                g                                                                                                                                                                ricotta cheese', '½                                                                                                                                                                teaspoon                                                                                                                                                                dried red chilli flakes', '1                                                                                                                                                                whole                                                                                                                                                                nutmeg                                                                                                                                                                , for grating', 'olive oil', '200                                                                                                                                                                g                                                                                                                                                                vac-packed chestnuts', '½                                                                                                                                                                a bunch of                                                                                                                                                                fresh sage                                                                                                                                                                , (15g)', '20                                                                                                                                                                g                                                                                                                                                                parmesan cheese                                                                                                                                                                , plus extra to serve', 'pasta', '1 x                                                                                                                                                                                                                     royal pasta dough', '75                                                                                                                                                                g                                                                                                                                                                baby spinach', 'semolina                                                                                                                                                                , for dusting', 'butter sauce', '100                                                                                                                                                                g                                                                                                                                                                unsalted butter', '4                                                                                                                                                                                                                    clementines', 'to serve', '50                                                                                                                                                                g                                                                                                                                                                skin-on almonds']\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_recipes[\"list_ingredients\"][552]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'easy veggie stir-fry'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_recipes[\"recipe\"][570]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vegan mushroom, chestnut & cranberry tart'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_recipes[\"recipe\"][490]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_recipes[\"list_ingredients\"][570]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_recipes[\"list_ingredients\"][490]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Fonction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv_char = CountVectorizer(analyzer='char_wb', ngram_range = (2,2))\n",
    "list_recipes = list(dfs[\"recipe\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_recipe():\n",
    "    '''gives the user an input , returns the result'''\n",
    "    user_recipe = input(\"Give me a recipe that you like:\")\n",
    "    return user_recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_recipe_name(user_recipe, list_recipes):\n",
    "    '''takes the result of the input , as well as the list of recipes of the database\n",
    "    user returns a df with the row containg the user recipe or the closest to it'''\n",
    "    list_recipes = list_recipes.append(user_recipe)\n",
    "    count_matrix = cv_char.fit_transform(list_recipes)\n",
    "    cosine_sim = cosine_similarity(count_matrix)\n",
    "    similar_recipes = list(enumerate(cosine_sim[-1]))\n",
    "    sorted_similar_recipes = sorted(similar_recipes,key=lambda x:x[1],reverse=True)[1:]\n",
    "    suggested_id = [d[0] for d in sorted_similar_recipes[:1]]\n",
    "    re_user = dfs.loc[suggested_id]\n",
    "    return re_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_final_recipe(vege_df, re_user):\n",
    "    cv = CountVectorizer()\n",
    "    df_search = pd.concat(vege_df, re_user, axis=0)\n",
    "    df_search = df_search.reset_index(drop=True)\n",
    "    list_features = list(df_search[\"lemmatized\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_recipe(suggested_ids):\n",
    "    print(f\"Top similar recipes to {user_recipe}\")\n",
    "    for x in suggested_ids:\n",
    "        final_recipes.loc[x]\n",
    "        name = final_recipes[\"recipe\"]\n",
    "        ingredients = final_recipes[\"list_ingredients\"]\n",
    "        steps = final_recipes[\"list_instructions\"]\n",
    "        if name and ingredients and steps: \n",
    "            print(f\"Recipe: {name}\")\n",
    "            print(f\"Ingredients: {ingredients}\")\n",
    "            print(f\"Steps: {steps}\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
